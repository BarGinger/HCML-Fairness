{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvGd4YgtppjR"
   },
   "source": [
    "## Submission instructions\n",
    "\n",
    "All code that you write should be in this notebook. Please include your names and student numbers. You have to submit this notebook, with your code and answers filled in. Make sure to add enough documentation.\n",
    "\n",
    "For questions, make use of the \"Lab\" session (see schedule).\n",
    "Questions can also be posted to the MS teams channel called \"Lab\".\n",
    "\n",
    "**Note:** You are free to make use of Python libraries (e.g., numpy, sklearn, etc.) except any *fairness* libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0P9dsbAffgfZ"
   },
   "source": [
    "#### Name and student numbers\n",
    "Bar Melinarskiy - 2482975\n",
    "\n",
    "Julia Baas - 6082826"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ni3V-7iqA6X"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "In this assignment we are going to use the **COMPAS** dataset.\n",
    "\n",
    "If you haven't done so already, take a look at this article: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n",
    "For background on the dataset, see https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm.\n",
    "\n",
    "**Reading in the COMPAS dataset**\n",
    "\n",
    "The dataset can be downloaded here: https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv\n",
    "\n",
    "For this assignment, we focus on the protected attribute *race*.\n",
    "\n",
    "The label (the variable we want to be able to predict) represents recidivism, which is defined as a new arrest within 2 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ajLXEdx6plgP",
    "outputId": "a65bf36a-1bc6-488f-accc-7bd9b24ca411"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget -c https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "id": "AaT9DQwwpqkx"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "compas_data = pd.read_csv('compas-scores-two-years.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsidUr4Bz-gZ"
   },
   "source": [
    "We apply several data preprocessing steps, including only retaining Caucasians and African Americans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "vs2eRxdgrHrt"
   },
   "outputs": [],
   "source": [
    "compas_data = compas_data[(compas_data.days_b_screening_arrest <= 30)\n",
    "            & (compas_data.days_b_screening_arrest >= -30)\n",
    "            & (compas_data.is_recid != -1)\n",
    "            & (compas_data.c_charge_degree != 'O')\n",
    "            & (compas_data.score_text != 'N/A')\n",
    "            & ((compas_data.race == 'Caucasian') | (compas_data.race == 'African-American'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5IwB6Rz2zIS"
   },
   "source": [
    "Take a look at the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WMM-MYdstObf",
    "outputId": "0bf826a7-bf28-433b-ea6a-b21c5f3f1fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id              name      first    last compas_screening_date     sex  \\\n",
      "1    3       kevon dixon      kevon   dixon            2013-01-27    Male   \n",
      "2    4          ed philo         ed   philo            2013-04-14    Male   \n",
      "6    8     edward riddle     edward  riddle            2014-02-19    Male   \n",
      "8   10  elizabeth thieme  elizabeth  thieme            2014-03-16  Female   \n",
      "10  14    benjamin franc   benjamin   franc            2013-11-26    Male   \n",
      "\n",
      "           dob  age       age_cat              race  ...  v_decile_score  \\\n",
      "1   1982-01-22   34       25 - 45  African-American  ...               1   \n",
      "2   1991-05-14   24  Less than 25  African-American  ...               3   \n",
      "6   1974-07-23   41       25 - 45         Caucasian  ...               2   \n",
      "8   1976-06-03   39       25 - 45         Caucasian  ...               1   \n",
      "10  1988-06-01   27       25 - 45         Caucasian  ...               4   \n",
      "\n",
      "    v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
      "1            Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
      "2            Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
      "6            Low        2014-02-19  2014-03-31   2014-04-18              14   \n",
      "8            Low        2014-03-16  2014-03-15   2014-03-18               0   \n",
      "10           Low        2013-11-26  2013-11-25   2013-11-26               0   \n",
      "\n",
      "   start  end event two_year_recid  \n",
      "1      9  159     1              1  \n",
      "2      0   63     0              1  \n",
      "6      5   40     1              1  \n",
      "8      2  747     0              0  \n",
      "10     0  857     0              0  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print(compas_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5vKapT6FtmvJ"
   },
   "source": [
    "Now take a look at the distribution of the protected attribute `race` and the distribution of our outcome variable `two_year_recid`.\n",
    "\n",
    "**Note:** in the context of fair machine learning, the favorable label here is no recidivism, i.e., ```two_year_recid = 0```. So think about how what you will code as the positive class in your machine learning experiments, and make sure your interpretation of the results is consistent with this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fh2oM2yptnjR",
    "outputId": "f89ff857-41d9-4a8c-d236-6fd4af65f177"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances per race category:\n",
      "race              two_year_recid\n",
      "African-American  1                 1661\n",
      "                  0                 1514\n",
      "Caucasian         0                 1281\n",
      "                  1                  822\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('Number of instances per race category:')\n",
    "print(compas_data[['race', 'two_year_recid']].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "636Yopp6wNtY"
   },
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hS3g2NT98dY_"
   },
   "source": [
    "### **1. Exploration**\n",
    "\n",
    "First we perform an exploratory analysis of the data.\n",
    "\n",
    "**Question:** What is the size of the data? (i.e. how many data instances does it contain?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "id": "k6FESAE1VmPu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5278, 53)\n",
      "Number of instances: 5278\n",
      "Number of features: 53\n",
      "Number of classes: 2\n",
      "Overall class distribution:\n",
      " two_year_recid  Count  Percentage\n",
      "              0   2795   52.955665\n",
      "              1   2483   47.044335\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "print(f\"Dataset shape: {compas_data.shape}\")\n",
    "dataset_size = len(compas_data)\n",
    "print(f\"Number of instances: {dataset_size}\")\n",
    "print(f\"Number of features: {len(compas_data.columns)}\")\n",
    "print(f\"Number of classes: {len(compas_data['two_year_recid'].unique())}\")\n",
    "\n",
    "print(\"Overall class distribution:\")\n",
    "distribution = compas_data['two_year_recid'].value_counts().reset_index()\n",
    "distribution.columns = ['two_year_recid', 'Count']\n",
    "distribution['Percentage'] = (distribution['Count'] / compas_data['two_year_recid'].count()) * 100\n",
    "print(distribution.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Answer:*** \n",
    "We have 5,278 instances in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kx-EDiJ41-_O"
   },
   "source": [
    "**Question:** In the dataset, the protected attribute is `race`, which has two categories: White and African Americans. How many data instances belong to each category?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "e9WqGTz5237Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall race distribution:\n",
      "            race  Count  Percentage\n",
      "African-American   3175   60.155362\n",
      "       Caucasian   2103   39.844638\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "print(\"Overall race distribution:\")\n",
    "feature = \"race\"\n",
    "distribution = compas_data[feature].value_counts().reset_index()\n",
    "distribution.columns = [feature, 'Count']\n",
    "distribution['Percentage'] = (distribution['Count'] / compas_data[feature].count()) * 100\n",
    "print(distribution.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DLdMWSNK3OPt"
   },
   "source": [
    "**Question:** What are the base rates (the probability of a favorable outcome for the two protected attribute classes)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "3OoqKyud3jIY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of the label (two_year_recid) by the protected feature (race):\n",
      "            race  Count_two_year_recid_0  Count_two_year_recid_1  Probability_two_year_recid_0  Probability_two_year_recid_1\n",
      "African-American                    1514                    1661                       0.47685                       0.52315\n",
      "       Caucasian                    1281                     822                       0.60913                       0.39087\n",
      "\n",
      "SO the base rates (two_year_recid = 0) and counts are:\n",
      "For African-American: Count=1514, Probability=0.477\n",
      "For Caucasian: Count=1281, Probability=0.609\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "protected_feature = \"race\"\n",
    "label = \"two_year_recid\"\n",
    "\n",
    "# Group by the protected feature and calculate the counts and proportions for each label value\n",
    "counts = compas_data.groupby(protected_feature)[label].value_counts(normalize=False).unstack().fillna(0)\n",
    "proportions = compas_data.groupby(protected_feature)[label].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# Reset the index for better readability\n",
    "counts = counts.reset_index()\n",
    "proportions = proportions.reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "counts.columns = [protected_feature] + [f\"Count_{label}_{i}\" for i in counts.columns[1:]]\n",
    "proportions.columns = [protected_feature] + [f\"Probability_{label}_{i}\" for i in proportions.columns[1:]]\n",
    "\n",
    "# Combine counts and proportions into a single DataFrame\n",
    "distribution = pd.merge(counts, proportions, on=protected_feature)\n",
    "\n",
    "# Print the combined DataFrame without the index\n",
    "print(\"\\nDistribution of the label (two_year_recid) by the protected feature (race):\")\n",
    "print(distribution.to_string(index=False))\n",
    "\n",
    "# Explicitly print the base rates and counts for the favorable outcome (two_year_recid = 0)\n",
    "print(\"\\nSO the base rates (two_year_recid = 0) and counts are:\")\n",
    "for _, row in distribution.iterrows():\n",
    "    print(f\"For {row[protected_feature]}: Count={row[f'Count_{label}_0']}, Probability={row[f'Probability_{label}_0']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr-0I7It3pBY"
   },
   "source": [
    "**Question:** What are the base rates for the combination of both race and sex categories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "3SCmOWs43t9r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Distribution of the label (two_year_recid) by the protected features (race, sex):\n",
      "            race    sex  Count_two_year_recid_0  Count_two_year_recid_1  Probability_two_year_recid_0  Probability_two_year_recid_1\n",
      "African-American Female                     346                     203                      0.630237                      0.369763\n",
      "African-American   Male                    1168                    1458                      0.444783                      0.555217\n",
      "       Caucasian Female                     312                     170                      0.647303                      0.352697\n",
      "       Caucasian   Male                     969                     652                      0.597779                      0.402221\n",
      "\n",
      "SO the base rates (two_year_recid = 0) and counts are:\n",
      "For race=African-American, sex=Female: Count=346, Probability=0.630\n",
      "For race=African-American, sex=Male: Count=1168, Probability=0.445\n",
      "For race=Caucasian, sex=Female: Count=312, Probability=0.647\n",
      "For race=Caucasian, sex=Male: Count=969, Probability=0.598\n"
     ]
    }
   ],
   "source": [
    "# Your code\n",
    "protected_features = [\"race\", \"sex\"]\n",
    "label = \"two_year_recid\"\n",
    "      \n",
    "# Group by the protected features and calculate the counts and proportions for each label value\n",
    "distribution = compas_data.groupby(protected_features)[label].value_counts(normalize=False).unstack().fillna(0)\n",
    "proportions = compas_data.groupby(protected_features)[label].value_counts(normalize=True).unstack().fillna(0)\n",
    "\n",
    "# Combine counts and proportions into a single DataFrame\n",
    "distribution = distribution.reset_index()\n",
    "proportions = proportions.reset_index()\n",
    "distribution.columns = protected_features + [f\"Count_{label}_{i}\" for i in distribution.columns[len(protected_features):]]\n",
    "proportions.columns = protected_features + [f\"Probability_{label}_{i}\" for i in proportions.columns[len(protected_features):]]\n",
    "combined = pd.merge(distribution, proportions, on=protected_features)\n",
    "\n",
    "# Print the combined DataFrame without the index\n",
    "print(\"\\nDistribution of the label (two_year_recid) by the protected features (race, sex):\")\n",
    "\n",
    "print(combined.to_string(index=False))\n",
    "\n",
    "# Explicitly print the base rates and counts for the favorable outcome (two_year_recid = 0)\n",
    "print(\"\\nSO the base rates (two_year_recid = 0) and counts are:\")\n",
    "for _, row in combined.iterrows():\n",
    "    feature_combination = \", \".join([f\"{feature}={row[feature]}\" for feature in protected_features])\n",
    "    print(f\"For {feature_combination}: Count={row[f'Count_{label}_0']}, Probability={row[f'Probability_{label}_0']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2qyyoS74UGC"
   },
   "source": [
    "**Question**\n",
    "\n",
    "Write down a short interpretation of the statistics you calculated. What do you see?\n",
    "> **Answer: Female offenders are less likely to become a recidivist than male offenders (0.630 over 0.445 and 0.647 over 0.598 for African-American and Caucasion respectively). Furthermore, African-American offenders are more likely to become a recidivist than Caucasian offenders (0.445 over 0.598 and 0.630 over 0.647 for male and female respectively).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-mxqnnUcaGc"
   },
   "source": [
    "### **2. Performance measures**\n",
    "\n",
    "You will have to measure the performance and fairness of different classifiers in question 5. The performance will be calculated with the precision, recall, F1 and accuracy.\n",
    "Additionally, you will have to calculate the statistical/demographic parity, the true positive rate (recall) and false positive rate per race group.\n",
    "\n",
    "Make sure that you are able to calculate these metrics in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "id": "IAO99gf2caZT"
   },
   "outputs": [],
   "source": [
    "# Your code for the performance measures\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "favorable_outcome = 0  # Define the favorable outcome (e.g., 0 for 'not recidivist')\n",
    "unfavorable_outcome = 1  # Define the unfavorable outcome (e.g., 1 for 'recidivist')\n",
    "\n",
    "# Function to calculate overall performance metrics\n",
    "def calculate_performance_metrics(y_true, y_pred):\n",
    "    metrics = {\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall (TPR)\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred)\n",
    "    }\n",
    "    df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Value'])\n",
    "    return df\n",
    "\n",
    "# Function to calculate statistical/demographic parity\n",
    "def calculate_statistical_parity(x, y_pred, protected_attribute):\n",
    "    parity = {}\n",
    "    y_groups = {g: y_pred.loc[df.index] for g, df in x.groupby(protected_attribute)}\n",
    "\n",
    "\n",
    "    for key, group in y_groups.items():\n",
    "        favorable_rate = np.mean( group == favorable_outcome)  # Favorable outcome is `0`\n",
    "        parity[key] = favorable_rate\n",
    "    df = pd.DataFrame.from_dict(parity, orient='index')\n",
    "    df.columns = ['Favorable Outcome Rate']\n",
    "    df.index = df.index.map(lambda x: 'Caucasian' if x == 1 else 'African-American')\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to calculate TPR and FPR per group\n",
    "def calculate_group_metrics(X, y_true, y_pred, protected_attribute):\n",
    "    group_metrics = {}\n",
    "    # Group the data by the protected attribute    \n",
    "    X_groups = {g: df.drop(columns=protected_attribute) for g, df in X.groupby(protected_attribute)}\n",
    "    \n",
    "    # Use the indices from the grouped X to split y_true and y_pred\n",
    "    y_true_groups = {g: y_true.loc[df.index] for g, df in X_groups.items()}\n",
    "    y_pred_groups = {g: y_pred.loc[df.index] for g, df in X_groups.items()}\n",
    "\n",
    "\n",
    "    for group in X_groups.keys():\n",
    "        # Get the corresponding y_true and y_pred groups\n",
    "        y_true_group = y_true_groups[group]\n",
    "        y_pred_group = y_pred_groups[group]\n",
    "        # True Positive Rate (TPR)\n",
    "        tpr = recall_score(y_true_group, y_pred_group, zero_division=0)\n",
    "        \n",
    "        # False Positive Rate (FPR)\n",
    "        fp = np.sum((y_pred_group == unfavorable_outcome) & (y_true_group == favorable_outcome))\n",
    "        tn = np.sum((y_pred_group == favorable_outcome) & (y_true_group == favorable_outcome))\n",
    "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "        \n",
    "        group_metrics[group] = {\"TPR\": tpr, \"FPR\": fpr}\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    group_metrics_df = pd.DataFrame.from_dict(group_metrics, orient='index')\n",
    "    \n",
    "    # Set the index to meaningful labels\n",
    "    group_metrics_df.index = group_metrics_df.index.map(lambda x: 'Caucasian' if x == 1 else 'African-American')\n",
    "\n",
    "    return group_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n51Bdpy59vhy"
   },
   "source": [
    "### **3. Prepare the data**\n",
    "For the classifiers in question 5, the input of the model can only contain numerical values, it is therefore important to convert the strings in the columns (features) of interest of the `compas_data` to floats or integers.\n",
    "\n",
    "The columns of interest are features that you think will be informative or interesting in predicting the outcome variable.\n",
    "Use the cell below to explore which of the Compas variables you need to convert to be able to use them for the classifiers.\n",
    "\n",
    "Generate a new dataframe with your selected features in the right encoding (also make sure to include `two_year_recid`). You can implement this yourself, or use the `LabelEncoder` from `sklearn`.\n",
    "\n",
    "**Note:** you do not need to convert all columns/features, only the ones you are interested in. However, do **not** include the feature `is_recid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5278 entries, 1 to 7212\n",
      "Data columns (total 53 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id                       5278 non-null   int64  \n",
      " 1   name                     5278 non-null   object \n",
      " 2   first                    5278 non-null   object \n",
      " 3   last                     5278 non-null   object \n",
      " 4   compas_screening_date    5278 non-null   object \n",
      " 5   sex                      5278 non-null   object \n",
      " 6   dob                      5278 non-null   object \n",
      " 7   age                      5278 non-null   int64  \n",
      " 8   age_cat                  5278 non-null   object \n",
      " 9   race                     5278 non-null   object \n",
      " 10  juv_fel_count            5278 non-null   int64  \n",
      " 11  decile_score             5278 non-null   int64  \n",
      " 12  juv_misd_count           5278 non-null   int64  \n",
      " 13  juv_other_count          5278 non-null   int64  \n",
      " 14  priors_count             5278 non-null   int64  \n",
      " 15  days_b_screening_arrest  5278 non-null   float64\n",
      " 16  c_jail_in                5278 non-null   object \n",
      " 17  c_jail_out               5278 non-null   object \n",
      " 18  c_case_number            5278 non-null   object \n",
      " 19  c_offense_date           4589 non-null   object \n",
      " 20  c_arrest_date            689 non-null    object \n",
      " 21  c_days_from_compas       5278 non-null   float64\n",
      " 22  c_charge_degree          5278 non-null   object \n",
      " 23  c_charge_desc            5273 non-null   object \n",
      " 24  is_recid                 5278 non-null   int64  \n",
      " 25  r_case_number            2647 non-null   object \n",
      " 26  r_charge_degree          2647 non-null   object \n",
      " 27  r_days_from_arrest       1781 non-null   float64\n",
      " 28  r_offense_date           2647 non-null   object \n",
      " 29  r_charge_desc            2606 non-null   object \n",
      " 30  r_jail_in                1781 non-null   object \n",
      " 31  r_jail_out               1781 non-null   object \n",
      " 32  violent_recid            0 non-null      float64\n",
      " 33  is_violent_recid         5278 non-null   int64  \n",
      " 34  vr_case_number           612 non-null    object \n",
      " 35  vr_charge_degree         612 non-null    object \n",
      " 36  vr_offense_date          612 non-null    object \n",
      " 37  vr_charge_desc           612 non-null    object \n",
      " 38  type_of_assessment       5278 non-null   object \n",
      " 39  decile_score.1           5278 non-null   int64  \n",
      " 40  score_text               5278 non-null   object \n",
      " 41  screening_date           5278 non-null   object \n",
      " 42  v_type_of_assessment     5278 non-null   object \n",
      " 43  v_decile_score           5278 non-null   int64  \n",
      " 44  v_score_text             5278 non-null   object \n",
      " 45  v_screening_date         5278 non-null   object \n",
      " 46  in_custody               5278 non-null   object \n",
      " 47  out_custody              5278 non-null   object \n",
      " 48  priors_count.1           5278 non-null   int64  \n",
      " 49  start                    5278 non-null   int64  \n",
      " 50  end                      5278 non-null   int64  \n",
      " 51  event                    5278 non-null   int64  \n",
      " 52  two_year_recid           5278 non-null   int64  \n",
      "dtypes: float64(4), int64(16), object(33)\n",
      "memory usage: 2.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(compas_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "2G0-QxbH95rX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5278 entries, 1 to 7212\n",
      "Data columns (total 6 columns):\n",
      " #   Column          Non-Null Count  Dtype\n",
      "---  ------          --------------  -----\n",
      " 0   sex             5278 non-null   int32\n",
      " 1   age             5278 non-null   int64\n",
      " 2   race            5278 non-null   int32\n",
      " 3   priors_count    5278 non-null   int64\n",
      " 4   juv_fel_count   5278 non-null   int64\n",
      " 5   two_year_recid  5278 non-null   int64\n",
      "dtypes: int32(2), int64(4)\n",
      "memory usage: 247.4 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#filtering only the features we find interesting:\n",
    "columns_to_keep = [\"sex\", \"age\", \"race\", \"priors_count\", \"juv_fel_count\", \"two_year_recid\"]\n",
    "new_dataset = compas_data[columns_to_keep].copy()\n",
    "\n",
    "#Converting sex values into 0 and 1\n",
    "new_dataset[\"sex\"] = (new_dataset[\"sex\"] == 'Male').astype(int) #Male = 1, female = 0\n",
    "new_dataset[\"race\"] = (new_dataset[\"race\"] == 'Caucasian').astype(int) #Caucasian = 1, A-A = 0\n",
    "\n",
    "#check it:\n",
    "print(new_dataset.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-ILbSsR-ZW_"
   },
   "source": [
    "**Question**\n",
    "\n",
    "Give a short motivation (one-two sentence) per feature why you think this is informative or interesting to take into account.\n",
    "> Answer: Sex is important to include because we saw that the reoffender scores differed, so it could be an indicator. Furthermore, the same holds for race and this was an important topic in the discussion on the COMPAS system. We also wanted to include age because young offenders have more time and are more likely to reoffend. This was also pointed out by ProPublica. The amount of prior offenses can also be a good indicator, since the offender already is a reoffender. The same logic holds for juvenile felony counts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkgRPopIxNVJ"
   },
   "source": [
    "### **4. Train and test split**\n",
    "\n",
    "Divide the dataset into a train (80%) and test split (20%), either by implementing it yourself, or by using an existing library.\n",
    "\n",
    "**Note:** Usually when carrying out machine learning experiments,\n",
    "we also need a dev set for developing and selecting our models (incl. tuning of hyper-parameters).\n",
    "However, in this assignment, the goal is not to optimize\n",
    "the performance of models so we'll only use a train and test split.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "G0wUGEpiV7mH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 4222 instances\n",
      "Testing set size: 1056 instances\n"
     ]
    }
   ],
   "source": [
    "# Your code to split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the features (X) and the target variable (y)\n",
    "label = \"two_year_recid\"\n",
    "X = new_dataset.drop(columns=[label])  # Drop the target column\n",
    "y = new_dataset[label]  # Target column\n",
    "\n",
    "# Split the dataset into training (80%) and testing (20%) setsm \n",
    "# using stratified sampling to maintain the distribution of the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Print the sizes of the splits\n",
    "print(f\"Training set size: {X_train.shape[0]} instances\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} instances\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kmq45GgAWEJo"
   },
   "source": [
    "### **5. Classifiers**\n",
    "\n",
    "Now, train and test different classifiers and report the following statistics:\n",
    "\n",
    "* Overall performance:\n",
    "\n",
    "  * Precision\n",
    "  * Recall\n",
    "  * F1\n",
    "  * Accuracy\n",
    "\n",
    "* Fairness performance:\n",
    "\n",
    "  * The statistical parity difference for the protected attribute `race`(i.e. the difference in the probability of receiving a favorable label between the two protected attribute groups);\n",
    "  * The true positive rates of the two protected attribute groups\n",
    "  * The false positive rates of the two protected attribute groups.\n",
    "\n",
    "For training the classifier we recommend using scikit-learn (https://scikit-learn.org/stable/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zu6eQ_3xGfXd"
   },
   "source": [
    "#### **5.1 Regular classification**\n",
    "Train a logistic regression classifier with the race feature and all other features that you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "id": "xDaGo07EWElK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logstic Regression with all chosen features\n",
      "\n",
      "****************************************************************\n",
      "The overall scores are:\n",
      "                 Value\n",
      "Precision     0.661327\n",
      "Recall (TPR)  0.581489\n",
      "F1 Score      0.618844\n",
      "Accuracy      0.662879\n",
      "\n",
      "****************************************************************\n",
      "The statistical parity difference for race is:\n",
      "                  Favorable Outcome Rate\n",
      "African-American                0.472089\n",
      "Caucasian                       0.752914\n",
      "\n",
      "****************************************************************\n",
      "The TPR and FPR of the two protected attribute groups:\n",
      "                       TPR       FPR\n",
      "African-American  0.678899  0.363333\n",
      "Caucasian         0.394118  0.150579\n"
     ]
    }
   ],
   "source": [
    "# Your code for classifier 1\n",
    "import pprint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# train the logistic regression model\n",
    "clf1 = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = pd.Series(clf1.predict(X_test))\n",
    "\n",
    "# Reset the indices of y_test and y_pred to match the original test dateset DataFrame\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_pred = y_pred.reset_index(drop=True)\n",
    "\n",
    "print(\"Logstic Regression with all chosen features\")\n",
    "print(\"\\n****************************************************************\")\n",
    "print(\"The overall scores are:\")\n",
    "df_1 = calculate_performance_metrics(y_test, y_pred)\n",
    "print(df_1.to_string())\n",
    "\n",
    "print(\"\\n****************************************************************\")\n",
    "print(\"The statistical parity difference for race is:\")\n",
    "df_2 = calculate_statistical_parity(X_test, y_pred, \"race\")\n",
    "pprint.pprint(df_2)\n",
    "\n",
    "print(\"\\n****************************************************************\")\n",
    "print(\"The TPR and FPR of the two protected attribute groups:\")\n",
    "df_3 = calculate_group_metrics(X_test, y_test, y_pred, \"race\")\n",
    "# df_2.index = df_2.index.map(lambda x: 'Caucasian' if x == 1 else 'African-American')\n",
    "pprint.pprint(df_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iM23AP8nFisw"
   },
   "source": [
    "#### **5.2 Without the protected attribute**\n",
    "Train a logistic regression classifier without the race feature, but with all other features you used in 5.1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "WL7LSSMPFmhv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logstic Regression without protected attribute (race)\n",
      "\n",
      "****************************************************************\n",
      "The overall scores are:\n",
      "                 Value\n",
      "Precision     0.657658\n",
      "Recall (TPR)  0.587525\n",
      "F1 Score      0.620616\n",
      "Accuracy      0.661932\n",
      "\n",
      "****************************************************************\n",
      "The statistical parity difference for race is:\n",
      "                  Favorable Outcome Rate\n",
      "African-American                0.473684\n",
      "Caucasian                       0.734266\n",
      "\n",
      "****************************************************************\n",
      "The TPR and FPR of the two protected attribute groups:\n",
      "                       TPR       FPR\n",
      "African-American  0.675841  0.363333\n",
      "Caucasian         0.417647  0.166023\n"
     ]
    }
   ],
   "source": [
    "# Your code for classifier 2\n",
    "import pprint\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#filtering the data without race:\n",
    "protected_features = ['race']\n",
    "X_without_protected = X_train.drop(columns=protected_features)\n",
    "X_test_without_protected = X_test.drop(columns=protected_features)\n",
    "\n",
    "# train the logistic regression model\n",
    "clf2 = LogisticRegression(random_state=0).fit(X_without_protected, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred_without = pd.Series(clf2.predict(X_test_without_protected))\n",
    "\n",
    "# Reset the indices of y_test and y_pred to match the original test dateset DataFrame\n",
    "X_test_without_protected = X_test_without_protected.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "y_pred_without = y_pred_without.reset_index(drop=True)\n",
    "\n",
    "print(\"Logstic Regression without protected attribute (race)\")\n",
    "print(\"\\n****************************************************************\")\n",
    "print(\"The overall scores are:\")\n",
    "df_1 = calculate_performance_metrics(y_test, y_pred_without)\n",
    "print(df_1.to_string())\n",
    "\n",
    "print(\"\\n****************************************************************\")\n",
    "print(\"The statistical parity difference for race is:\")\n",
    "df_2 = calculate_statistical_parity(X_test, y_pred_without, \"race\")\n",
    "pprint.pprint(df_2)\n",
    "\n",
    "print(\"\\n****************************************************************\")\n",
    "print(\"The TPR and FPR of the two protected attribute groups:\")\n",
    "df_3 = calculate_group_metrics(X_test, y_test, y_pred_without, \"race\")\n",
    "# df_2.index = df_2.index.map(lambda x: 'Caucasian' if x == 1 else 'African-American')\n",
    "pprint.pprint(df_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5H_mlbM6qij9"
   },
   "source": [
    "**Question**\n",
    "\n",
    "Write down a short interpretation of the results you calculated. What do you see?\n",
    "> Answer: The result is very similar. This means that adding the race doesn't make the system stronger. This is because race is not a good indicator for recidivism, the other features are stronger indicators. The outcome relies mostly on the other features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KwiX0vEXFlgU"
   },
   "source": [
    "#### **5.3 Pre-processing: Reweighing**\n",
    "Train and test a classifier with weights (see lecture slide for the weight calculation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "id": "G-1Vw1_xk4aQ"
   },
   "outputs": [],
   "source": [
    "# Your code for classifier 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yHv79yvv00a"
   },
   "source": [
    "**Question**\n",
    "\n",
    " Report the 4 weights that are used for reweighing and a short **interpretation/discussion** of the weights and the classifier results.\n",
    "> Answer:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C3XdW0qF82JC"
   },
   "source": [
    "#### **5.4 Post-processing: Equalized odds**\n",
    "Use the predictions by the first classifier for this post processing part (see lecture slides for more information about post processing for equalized odds).\n",
    "\n",
    "We have the following parameters (A indicates group membership, Y_{hat} the original prediction, Y_{tilde} the prediction of the derived predictor).\n",
    "\n",
    "* `p_00` = P(Y_{tilde} = 1 | Y_{hat} = 0 & A = 0)\n",
    "* `p_01` = P(Y_{tilde} = 1 | Y_{hat} = 0 & A = 1)\n",
    "* `p_10` = P(Y_{tilde} = 1 | Y_{hat} = 1 & A = 0)\n",
    "* `p_11` = P(Y_{tilde} = 1 | Y_{hat} = 1 & A = 1)\n",
    "\n",
    "\n",
    "Normally, the best parameters `p_00, p_01, p_10, p_11` are found with a linear program that minimizes loss between predictions of a derived predictor and the actual labels. In this assignment we will not ask you to do this. Instead, we would like you to follow the next steps to find parameters, post-process the data and check the performance of this classifier with post-processing:\n",
    "\n",
    "1. Generate 5000 different samples of these 4 parameters randomly;\n",
    "2. Write a function (or more) that applies these 4 parameters to postprocess the predictions.\n",
    "3. For each generated set of 4 parameters:\n",
    "  - Change the predicted labels with the function(s) from step 2;\n",
    "  - Evaluate these 'new' predictions, by calculating group-wise TPR and FPR, as well as overall performance based on F1 and/or accuracy.\n",
    "4. Choose the best set of parameters. Take into account the equalized odds fairness measure, as well a performance measure like accuracy or F1.\n",
    "5. Check the overall performance (precision, recall, accuracy, F1, etc.) of the new predictions after post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nk_scQdM76He"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 0): 0.5714025946899135, (0, 1): 0.4288890546751146, (1, 0): 0.5780913011344704, (1, 1): 0.20609823213950174}\n"
     ]
    }
   ],
   "source": [
    "# Your code for step 1\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# predictions for the first model\n",
    "y_pred = pd.Series(clf1.predict(X_test))\n",
    "\n",
    "# Generate random parameters for the model\n",
    "random_parameters = []\n",
    "for _ in range(5000):\n",
    "  p_00 = random.uniform(0, 1)\n",
    "  p_01 = random.uniform(0, 1)\n",
    "  p_10 = random.uniform(0, 1)\n",
    "  p_11 = random.uniform(0, 1)\n",
    "  random_parameters.append({(0, 0): p_00,\n",
    "                            (0, 1): p_01,\n",
    "                            (1, 0): p_10,\n",
    "                            (1, 1): p_11})\n",
    "\n",
    "# Example, first set of random parameters\n",
    "print(random_parameters[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0p92txObr6v"
   },
   "outputs": [],
   "source": [
    "# Your code for step 2\n",
    "# Create a dataframe with the necessary information\n",
    "df_post_data = pd.DataFrame({'race_num': X_test['race'],\n",
    "                             'pred_labels': y_pred,\n",
    "                             'true_labels': y_test})\n",
    "\n",
    "# the number of cases falling in each condition\n",
    "subset_sizes = {\n",
    "    (0, 0): len(df_post_data.query('pred_labels == 0 & race_num == 0')),\n",
    "    (0, 1): len(df_post_data.query('pred_labels == 0 & race_num == 1')),\n",
    "    (1, 0): len(df_post_data.query('pred_labels == 1 & race_num == 0')),\n",
    "    (1, 1): len(df_post_data.query('pred_labels == 1 & race_num == 1'))\n",
    "\n",
    "}\n",
    "\n",
    "def generate_labels(subset_sizes, p_dict):\n",
    "    \"\"\"\n",
    "    subset_sizes: dict with number of cases falling in each condition\n",
    "    p_dict: the postprocessing parameters\n",
    "    \"\"\"\n",
    "    new_predictions = {}\n",
    "\n",
    "    for (prediction, group), p in p_dict.items():\n",
    "\n",
    "      # The number of instances for which we need to generate labels\n",
    "      num_instances = subset_sizes[(prediction, group)]\n",
    "      \n",
    "      # Write your code here.\n",
    "      # Get labels and prediction of the current subgroup\n",
    "      y_tilde_for_subgroup = df_post_data.query(f'pred_labels == {prediction} & race_num == {group}')['pred_labels'].values\n",
    "\n",
    "      # flip the labels according to the postprocessing parameters\n",
    "      flip_mask = np.random.rand(num_instances) < p\n",
    "      y_tilde_for_subgroup_new = y_tilde_for_subgroup * (1 - flip_mask) + np.abs(y_tilde_for_subgroup-1) * flip_mask\n",
    "      # save the new predictions\n",
    "      new_predictions[(prediction, group)] = y_tilde_for_subgroup_new\n",
    "\n",
    "    return new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "id": "teZWyupiw2iM"
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[193], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Your code for step 3\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p_dict \u001b[38;5;129;01min\u001b[39;00m random_parameters:\n\u001b[1;32m----> 5\u001b[0m   new_predictions \u001b[38;5;241m=\u001b[39m generate_labels(subset_sizes, p_dict)\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;66;03m# replace the predictions\u001b[39;00m\n\u001b[0;32m      8\u001b[0m   df_copy \u001b[38;5;241m=\u001b[39m df_post_data\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[1;32mIn[192], line 37\u001b[0m, in \u001b[0;36mgenerate_labels\u001b[1;34m(subset_sizes, p_dict)\u001b[0m\n\u001b[0;32m     35\u001b[0m   y_tilde_for_subgroup_new \u001b[38;5;241m=\u001b[39m y_tilde_for_subgroup \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m flip_mask) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(y_tilde_for_subgroup\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m flip_mask\n\u001b[0;32m     36\u001b[0m   \u001b[38;5;66;03m# save the new predictions\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m   new_predictions[(prediction, group)] \u001b[38;5;241m=\u001b[39m y_tilde_for_subgroup_new\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_predictions\n",
      "File \u001b[1;32m<stringsource>:69\u001b[0m, in \u001b[0;36mcfunc.to_py.__Pyx_CFunc_b0409f__29_pydevd_sys_monitoring_cython_object__lParen__etc_to_py_4code_4line.wrap\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1465\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._line_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1507\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._internal_line_event\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1308\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._stop_on_breakpoint\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_sys_monitoring\\\\_pydevd_sys_monitoring_cython.pyx:1945\u001b[0m, in \u001b[0;36m_pydevd_sys_monitoring_cython._do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\bar24\\anaconda3\\envs\\ExplainableAI\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2185\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2182\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2184\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2185\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_wait_suspend(thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2187\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2190\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bar24\\anaconda3\\envs\\ExplainableAI\\Lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2254\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, trace_suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2251\u001b[0m                 queue\u001b[38;5;241m.\u001b[39mput(internal_cmd)\n\u001b[0;32m   2252\u001b[0m                 wait_timeout \u001b[38;5;241m=\u001b[39m TIMEOUT_FAST\n\u001b[1;32m-> 2254\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mwait(wait_timeout)\n\u001b[0;32m   2255\u001b[0m         notify_event\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m   2257\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\bar24\\anaconda3\\envs\\ExplainableAI\\Lib\\threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    653\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[1;32m--> 655\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[1;32mc:\\Users\\bar24\\anaconda3\\envs\\ExplainableAI\\Lib\\threading.py:359\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 359\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mTrue\u001b[39;00m, timeout)\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    361\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Your code for step 3\n",
    "\n",
    "for p_dict in random_parameters:\n",
    "\n",
    "  new_predictions = generate_labels(subset_sizes, p_dict)\n",
    "\n",
    "  # replace the predictions\n",
    "  df_copy = df_post_data.copy()\n",
    "\n",
    "  for (pred, group), p in p_dict.items():\n",
    "\n",
    "    new_preds = new_predictions[(pred,group)]\n",
    "    df_copy.loc[(df_post_data['pred_labels'] == pred) &\n",
    "                (df_post_data['race_num'] == group), 'pred_labels'] = new_preds\n",
    "\n",
    "\n",
    "  # evaluate the new predictions and save the scores\n",
    "  # Write your code here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-t-ZljWBBS9"
   },
   "outputs": [],
   "source": [
    "# Your code for step 4 and 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DD0weMlkN4Cq"
   },
   "source": [
    "**Question**\n",
    "\n",
    "Describe how you selected the best set of parameters. Furthermore, how do you interpret the best set of parameters that you found? And what do you think of the results of the new classifier?\n",
    ">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwtRtf1Pl5_u"
   },
   "source": [
    "#### **Overall discussion**\n",
    "For all 4 classifiers that you trained, describe:\n",
    "- Does this classifier satisfies statistical parity?\n",
    "- Does the classifier satisfy the equal opportunity criterion?\n",
    "\n",
    "Finally, how do the different classifiers compare against each other?\n",
    "\n",
    ">Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LUPZN32kOJ9H"
   },
   "source": [
    "### **6. Intersectional fairness**\n",
    "In the questions above `race` was the only protected attribute. However, multiple protected attributes sometimes interact, leading to different fairness outcomes for different combinations of these protected attributes.\n",
    "\n",
    "Now explore the intersectional fairness for protected attributes `race` and `sex` for the first two classifiers from question 5. Make a combination of the `race` and `sex` column, resulting in four new subgroups (e.g., female Caucasian), and report the maximum difference between the subgroups for statistical parity, TPR and FPR.\n",
    "For example, suppose we have four groups with TPRs 0.1, 0.2, 0.3, 0.8, then the maximum difference is 0.7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-siRd0cUH0sN"
   },
   "source": [
    "Your code to evaluate intersectional fairness for Classifier 1:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mSXG9sBjT-xX"
   },
   "outputs": [],
   "source": [
    "# Your code for intersectional fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oz_hNpkGH1ul"
   },
   "source": [
    "Your code to evaluate intersectional fairness for Classifier 2:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MwvWChS2H79s"
   },
   "outputs": [],
   "source": [
    "# Your code for intersectional fairness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pyE6wo8EH-E0"
   },
   "source": [
    "**Question**\n",
    "\n",
    "Write down a short interpretation of the results you calculated. What do you see?\n",
    "> Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lfFYnU1V_bl"
   },
   "source": [
    "## Discussion\n",
    "Provide a short ethical discussion (1 or 2 paragraphs) reflecting on these two aspects:\n",
    "\n",
    "1) The use of a ML system to try to predict recidivism;\n",
    "\n",
    "2) The public release of a dataset like this.\n",
    "\n",
    "> Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEjSKr56xiZO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ExplainableAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
